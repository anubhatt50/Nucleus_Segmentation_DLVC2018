{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import math\n",
    "import skimage.transform           # For resizing images\n",
    "import skimage.morphology          # For using image labeling\n",
    "import sklearn.model_selection     # For using KFold\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm         # Color map\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch_norm(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batch_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReLayNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReLayNet, self).__init__()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.drop1=nn.Dropout2d(p=0.3)\n",
    "        self.drop2=nn.Dropout2d(p=0.5)\n",
    "        self.drop3=nn.Dropout2d(p=0.5)\n",
    "\n",
    "        self.up1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.up2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.up3 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv1 = ConvBlock(3, 64)\n",
    "        self.conv2 = ConvBlock(64, 128)\n",
    "        self.conv3 = ConvBlock(128, 256)\n",
    "\n",
    "        self.conv4 = ConvBlock(256, 256)\n",
    "\n",
    "        self.conv5 = ConvBlock(512, 128)\n",
    "        self.conv6 = ConvBlock(256, 64)\n",
    "        self.conv7 = ConvBlock(128, 64)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        x, idx1 = self.pool1(c1)\n",
    "        x = self.drop1(x)\n",
    "        c2 = self.conv2(x)\n",
    "        x, idx2 = self.pool2(c2)\n",
    "        x = self.drop2(x)\n",
    "        c3 = self.conv3(x)\n",
    "        x, idx3 = self.pool3(c3)\n",
    "        x = self.drop3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.up1(x,idx3)\n",
    "        x = torch.cat([x, c3], 1)\n",
    "        x = self.conv5(x)\n",
    "        x = self.up2(x,idx2)\n",
    "        x = torch.cat([x, c2], 1)\n",
    "        x = self.conv6(x)\n",
    "        x = self.up3(x,idx1)\n",
    "        x = torch.cat([x, c1], 1)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net=ReLayNet()\n",
    "print(net)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATASETS (.PTH FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "x=train image set\n",
    "y=train image mask\n",
    "z=train image mask inverse\n",
    "v=train image boundaries\n",
    "a=train weights\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TrSNew.pth\")\n",
    "y=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TrMNew.pth\")\n",
    "z=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TrMInvNew.pth\")\n",
    "v=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TrBNew.pth\")\n",
    "a=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TrWNew.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "u=3 channel target ([mask:mask inverse:boundary])\n",
    "c=3 channel weight\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w=torch.cat([y,z],1)\n",
    "u=torch.cat([w,v],1)\n",
    "b=torch.cat([a,a],1)\n",
    "c=torch.cat([a,b],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "x2=test image set\n",
    "y2=test image mask\n",
    "z2=test image mask inverse\n",
    "v2=test image boundaries\n",
    "a2=test weights\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x2=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TsSNew.pth\")\n",
    "y2=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TsMNew.pth\")\n",
    "z2=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TsMInvNew.pth\")\n",
    "v2=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TsBNew.pth\")\n",
    "a2=torch.load(\"/home/histosr/Anuraag_Ranajoy/train2/TsWNew.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "u2=3 channel target ([mask:mask inverse:boundary])\n",
    "c2=3 channel weight\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2=torch.cat([y2,z2],1)\n",
    "u2=torch.cat([w2,v2],1)\n",
    "b2=torch.cat([a2,a2],1)\n",
    "c2=torch.cat([a2,b2],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining hyperparameters, batch-size and no. of epochs\n",
    "BatchSize=8\n",
    "iterations = 20\n",
    "lr=(4e-3)/0.85\n",
    "decayrate=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainloss = []\n",
    "testLoss1 = []\n",
    "testLoss2 = []\n",
    "start = time.time()\n",
    "\n",
    "count=0\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningloss = 0\n",
    "    net.train(True)   #train start\n",
    "    rn=torch.randperm(1382)\n",
    "    x=x[rn]\n",
    "    u=u[rn]\n",
    "    c=c[rn]\n",
    "    optimizer= optim.Adam(net.parameters(),lr=lr*decayrate*(count/4+1),betas=(0.9,0.99))\n",
    "    for i in range(0,1380,BatchSize):\n",
    "        inputs=x[i:i+BatchSize]\n",
    "        #normalising inputs\n",
    "        mean=torch.mean(torch.mean(inputs, dim=2),dim=2)\n",
    "        for m in range(mean.shape[0]):\n",
    "            for j in range(mean.shape[1]):\n",
    "                s=torch.std(inputs[m][j],unbiased=False)\n",
    "                inputs[m][j]=(inputs[m][j]-mean[m][j])/s\n",
    "        labels=u[i:i+BatchSize]\n",
    "        wt=c[i:i+BatchSize]\n",
    "        \n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        criterion=nn.BCEWithLogitsLoss(weight=wt.cuda())\n",
    "        loss = criterion(F.softmax(outputs), labels/255.)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        runningloss += loss.data[0]\n",
    " \n",
    "    avgTrainloss = runningloss/1380.0\n",
    "    trainloss.append(avgTrainloss)\n",
    "    \n",
    "    net.train(False) # For testing\n",
    "    test_runningLoss1 = 0    \n",
    "    for i in range(0,188,BatchSize):\n",
    "        \n",
    "        inputs=x2[i:i+BatchSize]\n",
    "        mean=torch.mean(torch.mean(inputs, dim=2),dim=2)\n",
    "        for m in range(mean.shape[0]):\n",
    "            for j in range(mean.shape[1]):\n",
    "                s=torch.std(inputs[m][j],unbiased=False)\n",
    "                inputs[m][j]=(inputs[m][j]-mean[m][j])/s\n",
    "        labels=u2[i:i+BatchSize]\n",
    "        wt=c2[i:i+BatchSize]\n",
    "        inputs, labels = Variable(inputs.cuda()),Variable(labels.cuda())\n",
    "        \n",
    "        outputs = net(inputs)       \n",
    "        \n",
    "        criterion=nn.BCEWithLogitsLoss(weight=wt.cuda())\n",
    "        \n",
    "        loss = criterion(F.softmax(outputs), labels/255.)      \n",
    "        \n",
    "        test_runningLoss1 += loss.data[0] \n",
    "        \n",
    "    avgTestLoss1 = test_runningLoss1/188.0    \n",
    "    testLoss1.append(avgTestLoss1)\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainloss,'r--',label='train')        \n",
    "    plt.plot(range(epoch+1),testLoss1,'g--',label='test') \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "      \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f}; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTrainloss,epochEnd//60,epochEnd%60))\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Testing Loss1: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTestLoss1,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING METRIC FOR EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_OBJECT_SIZE=15\n",
    "\n",
    "def imshow_args(x):\n",
    "    \"\"\"Matplotlib imshow arguments for plotting.\"\"\"\n",
    "    if len(x.shape)==2: return x, cm.gray\n",
    "    if x.shape[2]==1: return x[:,:,0], cm.gray\n",
    "    return x, None\n",
    "\n",
    "def get_labeled_mask(mask, cutoff=.5, min_object_size=MIN_OBJECT_SIZE):\n",
    "    \"\"\"Object segmentation by labeling the mask.\"\"\"\n",
    "    mask = mask.reshape(mask.shape[0], mask.shape[1])\n",
    "    lab_mask = skimage.morphology.label(mask > cutoff) \n",
    "    \n",
    "    # Keep only objects that are large enough.\n",
    "    (mask_labels, mask_sizes) = np.unique(lab_mask, return_counts=True)\n",
    "    if (mask_sizes < min_object_size).any():\n",
    "        mask_labels = mask_labels[mask_sizes < min_object_size]\n",
    "        for n in mask_labels:\n",
    "            lab_mask[lab_mask == n] = 0\n",
    "        lab_mask = skimage.morphology.label(lab_mask > .5) \n",
    "    \n",
    "    return lab_mask\n",
    "\n",
    "def get_iou(y_true_labeled, y_pred_labeled):\n",
    "    \"\"\"Compute non-zero intersections over unions.\"\"\"\n",
    "    # Array of different objects and occupied area.\n",
    "    (true_labels, true_areas) = np.unique(y_true_labeled, return_counts=True)\n",
    "    (pred_labels, pred_areas) = np.unique(y_pred_labeled, return_counts=True)\n",
    "\n",
    "    # Number of different labels.\n",
    "    n_true_labels = len(true_labels)\n",
    "    n_pred_labels = len(pred_labels)\n",
    "\n",
    "    # Each mask has at least one identified object.\n",
    "    if (n_true_labels > 1) and (n_pred_labels > 1):\n",
    "        \n",
    "        # Compute all intersections between the objects.\n",
    "        all_intersections = np.zeros((n_true_labels, n_pred_labels))\n",
    "        for i in range(y_true_labeled.shape[0]):\n",
    "            for j in range(y_true_labeled.shape[1]):\n",
    "                m = y_true_labeled[i,j]\n",
    "                n = y_pred_labeled[i,j]\n",
    "                all_intersections[m,n] += 1 \n",
    "\n",
    "        # Assign predicted to true background.\n",
    "        assigned = [[0,0]]\n",
    "        tmp = all_intersections.copy()\n",
    "        tmp[0,:] = -1\n",
    "        tmp[:,0] = -1\n",
    "\n",
    "        # Assign predicted to true objects if they have any overlap.\n",
    "        for i in range(1, np.min([n_true_labels, n_pred_labels])):\n",
    "            mn = list(np.unravel_index(np.argmax(tmp), (n_true_labels, n_pred_labels)))\n",
    "            if all_intersections[mn[0], mn[1]] > 0:\n",
    "                assigned.append(mn)\n",
    "            tmp[mn[0],:] = -1\n",
    "            tmp[:,mn[1]] = -1\n",
    "        assigned = np.array(assigned)\n",
    "\n",
    "        # Intersections over unions.\n",
    "        intersection = np.array([all_intersections[m,n] for m,n in assigned])\n",
    "        union = np.array([(true_areas[m] + pred_areas[n] - all_intersections[m,n]) \n",
    "                           for m,n in assigned])\n",
    "        iou = intersection / union\n",
    "\n",
    "        # Remove background.\n",
    "        iou = iou[1:]\n",
    "        assigned = assigned[1:]\n",
    "        true_labels = true_labels[1:]\n",
    "        pred_labels = pred_labels[1:]\n",
    "\n",
    "        # Labels that are not assigned.\n",
    "        true_not_assigned = np.setdiff1d(true_labels, assigned[:,0])\n",
    "        pred_not_assigned = np.setdiff1d(pred_labels, assigned[:,1])\n",
    "        \n",
    "    else:\n",
    "        # in case that no object is identified in one of the masks\n",
    "        iou = np.array([])\n",
    "        assigned = np.array([])\n",
    "        true_labels = true_labels[1:]\n",
    "        pred_labels = pred_labels[1:]\n",
    "        true_not_assigned = true_labels\n",
    "        pred_not_assigned = pred_labels\n",
    "        \n",
    "    # Returning parameters.\n",
    "    params = {'iou': iou, 'assigned': assigned, 'true_not_assigned': true_not_assigned,\n",
    "             'pred_not_assigned': pred_not_assigned, 'true_labels': true_labels,\n",
    "             'pred_labels': pred_labels}\n",
    "    return params\n",
    "\n",
    "def get_score_summary(y_true, y_pred):\n",
    "    \"\"\"Compute the score for a single sample including a detailed summary.\"\"\"\n",
    "    \n",
    "    y_true_labeled = get_labeled_mask(y_true)  \n",
    "    y_pred_labeled = get_labeled_mask(y_pred)  \n",
    "    \n",
    "    params = get_iou(y_true_labeled, y_pred_labeled)\n",
    "    iou = params['iou']\n",
    "    assigned = params['assigned']\n",
    "    true_not_assigned = params['true_not_assigned']\n",
    "    pred_not_assigned = params['pred_not_assigned']\n",
    "    true_labels = params['true_labels']\n",
    "    pred_labels = params['pred_labels']\n",
    "    n_true_labels = len(true_labels)\n",
    "    n_pred_labels = len(pred_labels)\n",
    "\n",
    "    summary = []\n",
    "    for i,threshold in enumerate(np.arange(0.5, 1.0, 0.05)):\n",
    "        tp = np.sum(iou > threshold)\n",
    "        fn = n_true_labels - tp\n",
    "        fp = n_pred_labels - tp\n",
    "        if (tp+fp+fn)>0: \n",
    "            prec = tp/(tp+fp+fn)\n",
    "        else: \n",
    "            prec = 0\n",
    "        summary.append([threshold, prec, tp, fp, fn])\n",
    "\n",
    "    summary = np.array(summary)\n",
    "    score = np.mean(summary[:,1]) # Final score.\n",
    "    params_dict = {'summary': summary, 'iou': iou, 'assigned': assigned, \n",
    "                   'true_not_assigned': true_not_assigned, \n",
    "                   'pred_not_assigned': pred_not_assigned, 'true_labels': true_labels,\n",
    "                   'pred_labels': pred_labels, 'y_true_labeled': y_true_labeled,\n",
    "                   'y_pred_labeled': y_pred_labeled}\n",
    "    \n",
    "    return score, params_dict\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    \"\"\"Compute the score for a batch of samples.\"\"\"\n",
    "    scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        score,_ = get_score_summary(y_true[i],y_pred[i])\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "def plot_score_summary(y_true, y_pred):\n",
    "    \"\"\"Plot score summary for a single sample.\"\"\"\n",
    "    # Compute score and assign parameters.\n",
    "    score, params_dict = get_score_summary(y_true, y_pred)\n",
    "    \n",
    "    assigned = params_dict['assigned']\n",
    "    true_not_assigned = params_dict['true_not_assigned']\n",
    "    pred_not_assigned = params_dict['pred_not_assigned']\n",
    "    true_labels = params_dict['true_labels']\n",
    "    pred_labels = params_dict['pred_labels']\n",
    "    y_true_labeled = params_dict['y_true_labeled']\n",
    "    y_pred_labeled = params_dict['y_pred_labeled']\n",
    "    summary = params_dict['summary']\n",
    "\n",
    "    n_assigned = len(assigned)\n",
    "    n_true_not_assigned = len(true_not_assigned)\n",
    "    n_pred_not_assigned = len(pred_not_assigned)\n",
    "    n_true_labels = len(true_labels)\n",
    "    n_pred_labels = len(pred_labels)\n",
    "\n",
    "    # Summary dataframe.\n",
    "    summary_df = pd.DataFrame(summary,columns=['threshold','precision','tp','fp','fn'])\n",
    "    print('Final score:', score)\n",
    "    print(summary_df)\n",
    "\n",
    "    # Plots.\n",
    "    fig, axs = plt.subplots(2,3,figsize=(20,13))\n",
    "\n",
    "    # True mask with true objects.\n",
    "    img = y_true\n",
    "    axs[0,0].imshow(img, cmap='gray')\n",
    "    #axs[0,0].set_title('{}.) true mask: {} true objects'.format(n,train_df['num_masks'][n]))\n",
    "\n",
    "    # True mask with identified objects.\n",
    "    #img = np.zeros(y_true.shape)\n",
    "    #img[y_true_labeled > 0.5] = 255\n",
    "    img, img_type = imshow_args(y_true_labeled)\n",
    "    axs[0,1].imshow(img, img_type)\n",
    "    #axs[0,1].set_title('{}.) true mask: {} objects identified'.format(n, n_true_labels))\n",
    "\n",
    "    # Predicted mask with identified objects.\n",
    "    #img = np.zeros(y_true.shape)\n",
    "    #img[y_pred_labeled > 0.5] = 255\n",
    "    img, img_type = imshow_args(y_pred_labeled)\n",
    "    axs[0,2].imshow(img, img_type)\n",
    "    axs[0,2].set_title('{}.) predicted mask: {} objects identified'.format(\n",
    "        n, n_pred_labels))\n",
    "\n",
    "    # Prediction overlap with true mask.\n",
    "    img = np.zeros(y_true.shape)\n",
    "    img[y_true > 0.5] = 100\n",
    "    for i,j in assigned: img[(y_true_labeled == i) & (y_pred_labeled == j)] = 255\n",
    "    axs[1,0].set_title('{}.) {} pred. overlaps (white) with true objects (gray)'.format(\n",
    "        n,len(assigned)))\n",
    "    axs[1,0].imshow(img, cmap='gray', norm=None)\n",
    "\n",
    "    # Intersection over union.\n",
    "    img = np.zeros(y_true.shape)\n",
    "    img[(y_pred_labeled > 0) & (y_pred_labeled < 100)] = 100\n",
    "    img[(y_true_labeled > 0) & (y_true_labeled < 100)] = 100\n",
    "    for i,j in assigned: img[(y_true_labeled == i) & (y_pred_labeled == j)] = 255\n",
    "    axs[1,1].set_title('{}.) {} intersections (white) over unions (gray)'.format(\n",
    "        n, n_assigned))\n",
    "    axs[1,1].imshow(img, cmap='gray');\n",
    "\n",
    "    # False positives and false negatives.\n",
    "    img = np.zeros(y_true.shape)\n",
    "    for i in pred_not_assigned: img[(y_pred_labeled == i)] = 255\n",
    "    for i in true_not_assigned: img[(y_true_labeled == i)] = 100\n",
    "    axs[1,2].set_title('{}.) no threshold: {} fp (white), {} fn (gray)'.format(\n",
    "        n, n_pred_not_assigned, n_true_not_assigned))\n",
    "    axs[1,2].imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALISING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "\n",
    "testImg = x2[n]\n",
    "testLab = u2[n].numpy()\n",
    "\n",
    "# Feed-forward \n",
    "segImg = net(Variable(testImg).unsqueeze(0).cuda())\n",
    "# Applying softmax to get class probabilities\n",
    "segImg_np = F.softmax(segImg).data.cpu().squeeze(0).numpy()\n",
    "segImg_np = (segImg_np>0.5)\n",
    "segImg_np = skimage.morphology.label(segImg_np)\n",
    "\n",
    "k2=testLab[0,:,:]\n",
    "k=segImg_np[0,:,:]\n",
    "\n",
    "plot_score_summary(k2,k)\n",
    "\n",
    "# Displaying segmented output and ground truth\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(231)\n",
    "plt.imshow(segImg_np[0,:,:],cmap='gray')\n",
    "plt.title('Channel 1')\n",
    "plt.subplot(232)\n",
    "plt.imshow(segImg_np[1,:,:],cmap='gray')\n",
    "plt.title('Channel 2')\n",
    "plt.subplot(233)\n",
    "plt.imshow(segImg_np[2,:,:],cmap='gray')\n",
    "plt.title('Channel 3')\n",
    "plt.subplot(234)\n",
    "plt.imshow(testLab[0,:,:],cmap='gray')\n",
    "plt.title('Channel 1')\n",
    "plt.subplot(235)\n",
    "plt.imshow(testLab[1,:,:],cmap='gray')\n",
    "plt.title('Channel 2')\n",
    "plt.subplot(236)\n",
    "plt.imshow(testLab[2,:,:],cmap='gray')\n",
    "plt.title('Channel 3')\n",
    "'''mean=torch.mean(torch.mean(testImg, dim=2),dim=2)\n",
    "    for m in range(mean.shape[0]):\n",
    "    for j in range(mean.shape[1]):\n",
    "        s=torch.std(testImg[m][j],unbiased=False)\n",
    "        testImg[m][j]=(testImg[m][j]-mean[m][j])/s'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING PTH FILE OF TEST IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create test dataset form images\n",
    "parentlabelpath = 'F:\\\\study material\\\\DL\\\\MICCAI2\\\\test-images\\\\'\n",
    "n=18 #no. of test images\n",
    "labeltensor=torch.FloatTensor(n, 3, 256, 256)\n",
    "for i in range(n):\n",
    "    img1 = cv2.imread(parentlabelpath + 'image ('+ str(i+1) + ').png')#load image\n",
    "    img1 = cv2.resize(img1,(256,256))\n",
    "    label=np.array(img1)\n",
    "    label=np.transpose(label, (2,0,1))\n",
    "    label = torch.from_numpy(label)\n",
    "    labeltensor[i] = label\n",
    "torch.save(labeltensor, parentlabelpath + 'filename.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load own testset\n",
    "x3=torch.load(\"filename.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALISE RESULT ON TEST IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=0 #sample no.\n",
    "\n",
    "testImg = x3[n]\n",
    "# Feed-forward \n",
    "segImg = net(Variable(testImg).unsqueeze(0).cuda())\n",
    "# Applying softmax to get class probabilities\n",
    "segImg_np = F.softmax(segImg).data.cpu().squeeze(0).numpy()\n",
    "segImg_np = (segImg_np>0.5)\n",
    "segImg_np = skimage.morphology.label(segImg_np)\n",
    "# Displaying segmented output\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(231)\n",
    "plt.imshow(segImg_np[0,:,:],cmap='gray')\n",
    "plt.title('Channel 1')\n",
    "plt.subplot(232)\n",
    "plt.imshow(segImg_np[1,:,:],cmap='gray')\n",
    "plt.title('Channel 2')\n",
    "plt.subplot(233)\n",
    "plt.imshow(segImg_np[2,:,:],cmap='gray')\n",
    "plt.title('Channel 3')\n",
    "plt.subplot(234)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
